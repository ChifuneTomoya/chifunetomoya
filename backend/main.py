# FastAPIæœ¬ä½“ã‚„å„ç¨®ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, constr
from jose import jwt
from jose.utils import base64url_decode
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.backends import default_backend
from dotenv import load_dotenv
from openai import OpenAI
import boto3
import os
import requests
import logging
from typing import List
import json

from openai.types.chat import ChatCompletionMessageToolCall

# ãƒ­ã‚®ãƒ³ã‚°åˆæœŸåŒ–
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

app = FastAPI()

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cognitoè¨­å®š
COGNITO_REGION = os.getenv("COGNITO_REGION")
USER_POOL_ID = os.getenv("COGNITO_USER_POOL_ID")
CLIENT_ID = os.getenv("COGNITO_CLIENT_ID")
COGNITO_ISSUER = f"https://cognito-idp.{COGNITO_REGION}.amazonaws.com/{USER_POOL_ID}"

try:
    JWKS = requests.get(f"{COGNITO_ISSUER}/.well-known/jwks.json").json()
except Exception as e:
    logger.error(f"JWKSå–å¾—å¤±æ•—: {e}")
    JWKS = None

# JWTæ¤œè¨¼
def jwk_to_public_key(jwk):
    e = int.from_bytes(base64url_decode(jwk["e"].encode()), "big")
    n = int.from_bytes(base64url_decode(jwk["n"].encode()), "big")
    return rsa.RSAPublicNumbers(e, n).public_key(default_backend())

def verify_jwt_token(request: Request) -> str:
    auth = request.headers.get("Authorization")
    if not auth or not auth.startswith("Bearer "):
        raise HTTPException(401, "èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    token = auth.split(" ")[1]

    if JWKS is None:
        raise HTTPException(500, "JWKSãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚")

    try:
        header = jwt.get_unverified_header(token)
        key = next(k for k in JWKS["keys"] if k["kid"] == header["kid"])
        rsa_key = jwk_to_public_key(key)
        claims = jwt.decode(
            token,
            rsa_key,
            algorithms=["RS256"],
            audience=CLIENT_ID,
            issuer=COGNITO_ISSUER,
        )
        return claims.get("email", "unknown")
    except Exception as e:
        raise HTTPException(401, f"ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
bedrock_client = boto3.client(
    "bedrock-agent-runtime",
    region_name=os.getenv("AWS_REGION"),
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
)

openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

KNOWLEDGE_BASE_ID = os.getenv("BEDROCK_KNOWLEDGE_BASE_ID")
MODEL_ARN = os.getenv("BEDROCK_MODEL_ARN")

# Pydanticãƒ¢ãƒ‡ãƒ«
class StudyInput(BaseModel):
    question: constr(min_length=1, max_length=500)  # type: ignore
    category: constr(min_length=1, max_length=50)   # type: ignore

last_sources = {}

@app.post("/study")
async def study(data: StudyInput, email: str = Depends(verify_jwt_token)):
    try:
        prev_source = last_sources.get(email)

        input_text = f"""
ã‚ãªãŸã¯ãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œç´¢+å•é¡Œç”ŸæˆAIã§ã™ã€‚
ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ã¦ã€**å•é¡Œã‚’5å•ç”Ÿæˆã—ã¦ãã ã•ã„**ã€‚
â€»åŒã˜å•é¡ŒãŒé€£ç¶šã—ãªã„ã‚ˆã†æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

å•é¡Œå†…å®¹:ã€Œ{data.question}ã€ãŒç©ºã®ã¨ãã¯ã€ä¸‹è¨˜ã«è¨˜è¼‰ã—ã¦ã‚ã‚‹ã€ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã«æ²¿ã£ã¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:
-ã‚«ãƒ†ã‚´ãƒªã€Œ{data.category}ã€ãŒã€Œå•é¡Œé›†ã€ã®å ´åˆã¯ `questions.pdf` ã ã‘ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
-ã‚«ãƒ†ã‚´ãƒªã€Œ{data.category}ã€ãŒã€ŒåŸºæœ¬æƒ…å ±ã€ã®å ´åˆã¯ã€`2024r06_fe_kamoku_a_qs.pdf`ã¨ `2024r06_fe_kamoku_a_ans.pdf` ã‹ã‚‰å•é¡Œã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
åŸºæœ¬æƒ…å ±ã‚«ãƒ†ã‚´ãƒªã«ã¯ã€ä»¥ä¸‹ã®2ç¨®é¡ã®PDFãŒå­˜åœ¨ã—ã¾ã™ã€‚

- `2024r06_fe_kamoku_a_qs.pdf`ï¼šå•é¡Œç•ªå·ã¨å•é¡Œæ–‡ã¨é¸æŠè‚¢ï¼ˆã‚¢ã€œã‚¨ï¼‰ãŒæ²è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚
- `2024r06_fe_kamoku_a_ans.pdf`ï¼šå•é¡Œç•ªå·ã¨æ­£è§£è‚¢ï¼ˆã‚¢ã€œã‚¨ï¼‰ãŒæ²è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚

ã“ã®2ã¤ã®PDFã‚’ç…§åˆã—ã€è©²å½“ã™ã‚‹å•é¡Œã«å¯¾ã™ã‚‹ã€Œå•é¡Œç•ªå·ãƒ»å•é¡Œæ–‡ãƒ»é¸æŠè‚¢ãƒ»æ­£è§£ã€ã‚’çµ„ã¿åˆã‚ã›ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ç…§åˆã§ããªã‹ã£ãŸå ´åˆã¯ã€æ¤œç´¢ã‹ã‚‰å¤–ã—ã¦ãã ã•ã„ã€‚
å•é¡Œã¯å•1ã‹ã‚‰å•20ã¾ã§ã‚ã‚Šã¾ã™ã€‚ãŸã ã—ã€å•é¡Œæ–‡ã‚„è§£ç­”ã«å›³å½¢ãŒå…¥ã£ã¦ã„ã‚‹å•é¡Œã¯ç”Ÿæˆã—ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
é¡Œæ–‡: X åŠã³ Y ã¯ãã‚Œãã‚Œ 0 åˆã¯ 1 ã®å€¤ã‚’ã¨ã‚‹å¤‰æ•°ã§ã‚ã‚‹ã€‚X â–¡Y ã‚’ X ã¨ Y ã®è«–ç†æ¼”ç®—ã¨ã—ãŸã¨ãï¼Œæ¬¡ã®çœŸç†å€¤è¡¨ãŒå¾—ã‚‰ã‚ŒãŸã€‚X â–¡Y ã®çœŸç†å€¤è¡¨ã¯ã©ã‚Œã‹ã€‚ã“ã®å•é¡Œã¯ç”Ÿæˆã—ãªã„ã§ãã ã•ã„ã€‚

------------------------------------
ã‚«ãƒ†ã‚´ãƒªãŒå•é¡Œé›†ã®å ´åˆ
ã€å•é¡Œé›†ã€‘
`questions.pdf`ã¯6ãƒšãƒ¼ã‚¸ã€50å•ã‚ã‚Šã¾ã™ã€‚
å‡ºåŠ›å½¢å¼ï¼ˆä¾‹ï¼‰ï¼š
Q1: ã€œï¼Ÿ
A1: ã€œï¼ˆè§£èª¬ï¼‰ "å‡ºå±•ãƒšãƒ¼ã‚¸": "ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒšãƒ¼ã‚¸ç•ªå·ãªã©"

Q2: ...
...
------------------------------------

------------------------------------
ã‚«ãƒ†ã‚´ãƒªãŒåŸºæœ¬æƒ…å ±ã®å ´åˆ
ã€åŸºæœ¬æƒ…å ±ã€‘
`2024r06_fe_kamoku_a_qs.pdf`ã¨`2024r06_fe_kamoku_a_ans.pdf`ã ã‘ä½¿ã£ã¦ä¸‹ã•ã„ã€‚
å‡ºåŠ›å½¢å¼ï¼ˆä¾‹ï¼‰ï¼š
å•é¡Œç•ªå·:
å•é¡Œæ–‡:
é¸æŠè‚¢:
è§£ç­”:
å‡ºå±•ãƒšãƒ¼ã‚¸": "ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒšãƒ¼ã‚¸ç•ªå·ãªã©"
-------------------------------------

ã€ç‰¹è¨˜äº‹é …ã€‘
- ã€Œ{prev_source}ã€ã®ãƒšãƒ¼ã‚¸ä»¥å¤–ã‹ã‚‰é¸ã³ã€å†…å®¹ãŒå‰å›ã¨æ˜ç¢ºã«ç•°ãªã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª:ã€Œ{data.category}ã€
å•é¡Œå†…å®¹:ã€Œ{data.question}ã€

"""

        logger.info(f"ã‚«ãƒ†ã‚´ãƒª: {data.category} | å®Ÿéš›ã®è³ªå•ï¼ˆæ¤œç´¢ç”¨ï¼‰: {data.question or 'ï¼ˆAIã«ã‚ˆã‚‹è‡ªå‹•ç”Ÿæˆï¼‰'}")

        # Bedrockã«å•ã„åˆã‚ã›
        response = bedrock_client.retrieve_and_generate(
            input={"text": input_text},
            retrieveAndGenerateConfiguration={
                "type": "KNOWLEDGE_BASE",
                "knowledgeBaseConfiguration": {
                    "knowledgeBaseId": KNOWLEDGE_BASE_ID,
                    "modelArn": MODEL_ARN,
                    "generationConfiguration": {
                        "inferenceConfig": {
                            "textInferenceConfig": {
                                "temperature": 0.8,
                                "topP": 0.7
                            }
                        }
                    }
                }
            }
        )

        intermediate_answer = response.get("output", {}).get("text", "").strip()
        logger.info("Claudeä¸­é–“å›ç­”: %s", intermediate_answer)

        if not intermediate_answer:
            raise HTTPException(500, "Claudeã‹ã‚‰æœ‰åŠ¹ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        # å‡ºå…¸æŠ½å‡º
        # âœ… citationsã‚’å–å¾—ã—ã€å‡ºå…¸æƒ…å ±ã‚’æŠ½å‡º
        citations = response.get("citations", [])
        source_infos = []
        for citation in citations:
            for ref in citation.get("retrievedReferences", []):
                try:
                    page = int(ref.get("metadata", {}).get("x-amz-bedrock-kb-document-page-number", 0))
                    uri = ref.get("location", {}).get("s3Location", {}).get("uri", "")
                    filename = uri.split("/")[-1] if uri else "questions.pdf"
                    source_infos.append(f"{filename} {page}ãƒšãƒ¼ã‚¸")
                except Exception as e:
                    logger.warning(f"å‡ºå…¸æƒ…å ±ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        if source_infos:
            # AIå›ç­”ã®ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã«æ­£ç¢ºãªå‡ºå…¸ã‚’è¿½è¨˜
            intermediate_answer += "\n\nï¼ˆå‡ºå…¸: " + " / ".join(source_infos) + "ï¼‰"


        # ğŸ”§ Structured Outputã§ã‚¯ã‚¤ã‚ºç”Ÿæˆ
        openai_response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ•™è‚²ã‚¢ãƒ—ãƒªã®AIè¬›å¸«ã§ã™ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®æ•™æã‹ã‚‰1å•ã ã‘é¸ã‚“ã§ã€ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n{intermediate_answer}"}
            ],
            functions=[
                {
                    "name": "generate_quiz",
                    "description": "1å•ã®4æŠå•é¡Œã‚’ç”Ÿæˆã™ã‚‹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "å•é¡Œæ–‡": {"type": "string"},
                            "é¸æŠè‚¢": {
                                "type": "array",
                                "items": {"type": "string"},
                                "minItems": 4,
                                "maxItems": 4
                            },
                            "æ­£è§£": {"type": "string"},
                            "è§£èª¬": {"type": "string"},
                            "å‡ºå…¸ãƒšãƒ¼ã‚¸": {"type": "string"},
                        },
                        "required": ["å•é¡Œæ–‡", "é¸æŠè‚¢", "æ­£è§£", "è§£èª¬", "å‡ºå…¸ãƒšãƒ¼ã‚¸"]
                    }
                }
            ],
            function_call={"name": "generate_quiz"},
            temperature=0.3,
        )

        function_call: ChatCompletionMessageToolCall = openai_response.choices[0].message.function_call
        arguments = json.loads(function_call.arguments)

        # ğŸ”§ æ­£è§£ã‚’Aã€œDã«å¤‰æ›
        correct_text = arguments["æ­£è§£"]
        choices = arguments["é¸æŠè‚¢"]
        if correct_text in choices:
            index = choices.index(correct_text)
            arguments["æ­£è§£"] = ["A", "B", "C", "D"][index]
        else:
            logger.warning(f"æ­£è§£ãŒé¸æŠè‚¢ã«ä¸€è‡´ã—ã¾ã›ã‚“: {correct_text}")

        return {
            "user": email,
            "question": data.question or "ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰",
            "quiz": arguments,
        }

    except Exception as e:
        logger.exception("å•é¡Œç”Ÿæˆä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        raise HTTPException(500, "AIã‹ã‚‰ã®ã‚¯ã‚¤ã‚ºç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")