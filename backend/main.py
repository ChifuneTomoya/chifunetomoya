# FastAPIæœ¬ä½“ã‚„å„ç¨®ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, constr
from jose import jwt
from jose.utils import base64url_decode
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.backends import default_backend
from dotenv import load_dotenv
from openai import OpenAI
import boto3
import os
import requests
import logging
from typing import List
import json

from openai.types.chat import ChatCompletionMessageToolCall

# ãƒ­ã‚®ãƒ³ã‚°åˆæœŸåŒ–
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

app = FastAPI()

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cognitoè¨­å®š
COGNITO_REGION = os.getenv("COGNITO_REGION")
USER_POOL_ID = os.getenv("COGNITO_USER_POOL_ID")
CLIENT_ID = os.getenv("COGNITO_CLIENT_ID")
COGNITO_ISSUER = f"https://cognito-idp.{COGNITO_REGION}.amazonaws.com/{USER_POOL_ID}"

try:
    JWKS = requests.get(f"{COGNITO_ISSUER}/.well-known/jwks.json").json()
except Exception as e:
    logger.error(f"JWKSå–å¾—å¤±æ•—: {e}")
    JWKS = None

# JWTæ¤œè¨¼
def jwk_to_public_key(jwk):
    e = int.from_bytes(base64url_decode(jwk["e"].encode()), "big")
    n = int.from_bytes(base64url_decode(jwk["n"].encode()), "big")
    return rsa.RSAPublicNumbers(e, n).public_key(default_backend())

def verify_jwt_token(request: Request) -> str:
    auth = request.headers.get("Authorization")
    if not auth or not auth.startswith("Bearer "):
        raise HTTPException(401, "èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    token = auth.split(" ")[1]

    if JWKS is None:
        raise HTTPException(500, "JWKSãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚")

    try:
        header = jwt.get_unverified_header(token)
        key = next(k for k in JWKS["keys"] if k["kid"] == header["kid"])
        rsa_key = jwk_to_public_key(key)
        claims = jwt.decode(
            token,
            rsa_key,
            algorithms=["RS256"],
            audience=CLIENT_ID,
            issuer=COGNITO_ISSUER,
        )
        return claims.get("email", "unknown")
    except Exception as e:
        raise HTTPException(401, f"ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
bedrock_client = boto3.client(
    "bedrock-agent-runtime",
    region_name=os.getenv("AWS_REGION"),
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
)

openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

KNOWLEDGE_BASE_ID = os.getenv("BEDROCK_KNOWLEDGE_BASE_ID")
MODEL_ARN = os.getenv("BEDROCK_MODEL_ARN")

# Pydanticãƒ¢ãƒ‡ãƒ«
class StudyInput(BaseModel):
    question: constr(min_length=1, max_length=500)  # type: ignore
    category: constr(min_length=1, max_length=50)   # type: ignore

last_sources = {}

@app.post("/study")
async def study(data: StudyInput, email: str = Depends(verify_jwt_token)):
    try:
        prev_source = last_sources.get(email)

        input_text = f"""
ã‚ãªãŸã¯ãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œç´¢+å•é¡Œç”ŸæˆAIã§ã™ã€‚

`questions.pdf`ã®æƒ…å ±ã ã‘ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

å•é¡Œå†…å®¹:ã€Œ{data.question}ã€ãŒç©ºã®ã¨ãã¯ã€å•é¡Œã‚’5å•ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

â€»åŒã˜å•é¡ŒãŒé€£ç¶šã—ãªã„ã‚ˆã†æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
â€»å„å•é¡Œã”ã¨ã«æ­£ã—ã„ã€Œå‡ºå…¸: questions.pdf Xãƒšãƒ¼ã‚¸ã€ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ï¼ˆå…¨ä½“ã«1ã¤ã§ã¯ãªãã€å€‹åˆ¥ã«ä»˜ã‘ã¦ãã ã•ã„ï¼‰

å‡ºåŠ›å½¢å¼ï¼ˆä¾‹ï¼‰:
Q1: ã€œï¼Ÿ
A1: ã€œï¼ˆè§£èª¬ï¼‰
å‡ºå…¸: questions.pdf 1ãƒšãƒ¼ã‚¸

...

ã€ç‰¹è¨˜äº‹é …ã€‘
- ã€Œ{prev_source}ã€ã®ãƒšãƒ¼ã‚¸ä»¥å¤–ã‹ã‚‰é¸ã³ã€å†…å®¹ãŒå‰å›ã¨æ˜ç¢ºã«ç•°ãªã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª:ã€Œ{data.category}ã€
å•é¡Œå†…å®¹:ã€Œ{data.question}ã€
"""

        logger.info(f"ã‚«ãƒ†ã‚´ãƒª: {data.category} | å®Ÿéš›ã®è³ªå•ï¼ˆæ¤œç´¢ç”¨ï¼‰: {data.question or 'ï¼ˆAIã«ã‚ˆã‚‹è‡ªå‹•ç”Ÿæˆï¼‰'}")

        # Bedrockã«å•ã„åˆã‚ã›
        response = bedrock_client.retrieve_and_generate(
            input={"text": input_text},
            retrieveAndGenerateConfiguration={
                "type": "KNOWLEDGE_BASE",
                "knowledgeBaseConfiguration": {
                    "knowledgeBaseId": KNOWLEDGE_BASE_ID,
                    "modelArn": MODEL_ARN,
                    "generationConfiguration": {
                        "inferenceConfig": {
                            "textInferenceConfig": {
                                "temperature": 1.0,
                                "topP": 0.95
                            }
                        }
                    }
                }
            }
        )

        intermediate_answer = response.get("output", {}).get("text", "").strip()
        logger.info("Claudeä¸­é–“å›ç­”: %s", intermediate_answer)

        if not intermediate_answer:
            raise HTTPException(500, "Claudeã‹ã‚‰æœ‰åŠ¹ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        # å‡ºå…¸æŠ½å‡º
        source_info = ""
        citations = response.get("citations", [])
        if citations:
            try:
                ref = citations[0]["retrievedReferences"][0]
                page = int(ref.get("metadata", {}).get("x-amz-bedrock-kb-document-page-number", 0))
                uri = ref.get("location", {}).get("s3Location", {}).get("uri", "")
                filename = uri.split("/")[-1] if uri else "è³‡æ–™"
                source_info = f"{filename} {page}ãƒšãƒ¼ã‚¸"
                intermediate_answer += f"\n\nï¼ˆå‡ºå…¸: {source_info}ï¼‰"
                last_sources[email] = source_info
            except Exception as e:
                logger.warning(f"å‡ºå…¸æƒ…å ±ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # ğŸ”§ Structured Outputã§ã‚¯ã‚¤ã‚ºç”Ÿæˆ
        openai_response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ•™è‚²ã‚¢ãƒ—ãƒªã®AIè¬›å¸«ã§ã™ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®æ•™æã‹ã‚‰1å•ã ã‘ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n{intermediate_answer}"}
            ],
            functions=[
                {
                    "name": "generate_quiz",
                    "description": "1å•ã®4æŠå•é¡Œã‚’ç”Ÿæˆã™ã‚‹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "å•é¡Œæ–‡": {"type": "string"},
                            "é¸æŠè‚¢": {
                                "type": "array",
                                "items": {"type": "string"},
                                "minItems": 4,
                                "maxItems": 4
                            },
                            "æ­£è§£": {"type": "string"},
                            "è§£èª¬": {"type": "string"},
                            "å‡ºå±•ãƒšãƒ¼ã‚¸": {"type": "string"},
                        },
                        "required": ["å•é¡Œæ–‡", "é¸æŠè‚¢", "æ­£è§£", "è§£èª¬", "å‡ºå±•ãƒšãƒ¼ã‚¸"]
                    }
                }
            ],
            function_call={"name": "generate_quiz"},
            temperature=0.3,
        )

        function_call: ChatCompletionMessageToolCall = openai_response.choices[0].message.function_call
        arguments = json.loads(function_call.arguments)

        # ğŸ”§ æ­£è§£ã‚’Aã€œDã«å¤‰æ›
        correct_text = arguments["æ­£è§£"]
        choices = arguments["é¸æŠè‚¢"]
        if correct_text in choices:
            index = choices.index(correct_text)
            arguments["æ­£è§£"] = ["A", "B", "C", "D"][index]
        else:
            logger.warning(f"æ­£è§£ãŒé¸æŠè‚¢ã«ä¸€è‡´ã—ã¾ã›ã‚“: {correct_text}")

        return {
            "user": email,
            "question": data.question or "ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰",
            "quiz": arguments,
        }

    except Exception as e:
        logger.exception("å•é¡Œç”Ÿæˆä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        raise HTTPException(500, "AIã‹ã‚‰ã®ã‚¯ã‚¤ã‚ºç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                            
@app.post("/generate_quiz")
async def generate_quiz(data: StudyInput, email: str = Depends(verify_jwt_token)):
    prompt = f"""
ä»¥ä¸‹ã®å½¢å¼ã§1å•ã®4æŠã‚¯ã‚¤ã‚ºã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{{
  "å•é¡Œæ–‡": "...",
  "é¸æŠè‚¢": ["A", "B", "C", "D"],
  "æ­£è§£": "",
  "è§£èª¬": "..."
}}

ã‚«ãƒ†ã‚´ãƒª: {data.category}
è³ªå•: {data.question}
"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )
        quiz_text = response.choices[0].message.content.strip()
        quiz_data = json.loads(quiz_text)
        return {"quiz": quiz_data}

    except json.JSONDecodeError as e:
        raise HTTPException(500, f"JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\nå†…å®¹: {quiz_text}")
    except Exception as e:
        raise HTTPException(500, f"ã‚¯ã‚¤ã‚ºç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
